# HelloAgents é…ç½®æŒ‡å—

> ğŸ”§ è¯¦ç»†çš„ç¯å¢ƒé…ç½®å’ŒLLMæä¾›å•†è®¾ç½®æŒ‡å—

## ğŸ“‹ ç›®å½•

- [å¿«é€Ÿé…ç½®](#å¿«é€Ÿé…ç½®)
- [LLMæä¾›å•†é…ç½®](#llmæä¾›å•†é…ç½®)
- [å·¥å…·é…ç½®](#å·¥å…·é…ç½®)
- [é«˜çº§é…ç½®](#é«˜çº§é…ç½®)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## ğŸš€ å¿«é€Ÿé…ç½®

### 1. åˆ›å»ºç¯å¢ƒé…ç½®æ–‡ä»¶

```bash
# å¤åˆ¶ç¤ºä¾‹é…ç½®æ–‡ä»¶
cp .env.example .env
```

### 2. é…ç½®LLMæœåŠ¡

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œé…ç½®ä»¥ä¸‹4ä¸ªæ ¸å¿ƒå˜é‡ï¼š

```bash
# æ¨¡å‹åç§°
LLM_MODEL_ID=your-model-name

# APIå¯†é’¥
LLM_API_KEY=your-api-key-here

# æœåŠ¡åœ°å€
LLM_BASE_URL=your-api-base-url

# è¶…æ—¶æ—¶é—´ï¼ˆå¯é€‰ï¼Œé»˜è®¤60ç§’ï¼‰
LLM_TIMEOUT=60
```

### 3. éªŒè¯é…ç½®

```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®åŠ è½½
python -c "
import os
from dotenv import load_dotenv
load_dotenv()
print('ğŸ”§ ç¯å¢ƒå˜é‡æ£€æŸ¥:')
print(f'LLM_MODEL_ID: {os.getenv(\"LLM_MODEL_ID\", \"æœªè®¾ç½®\")}')
print(f'LLM_API_KEY: {\"å·²è®¾ç½®\" if os.getenv(\"LLM_API_KEY\") else \"æœªè®¾ç½®\"}')
print(f'LLM_BASE_URL: {os.getenv(\"LLM_BASE_URL\", \"æœªè®¾ç½®\")}')
"

# æµ‹è¯•LLMè¿æ¥ï¼ˆéœ€è¦å…ˆé…ç½®å¥½.envæ–‡ä»¶ï¼‰
python -c "
from hello_agents import HelloAgentsLLM
try:
    llm = HelloAgentsLLM()
    print(f'âœ… æ£€æµ‹åˆ°provider: {llm.provider}')
    print(f'âœ… æ¨¡å‹: {llm.model}')
    print('âœ… é…ç½®éªŒè¯æˆåŠŸ')
except Exception as e:
    print(f'âŒ é…ç½®éªŒè¯å¤±è´¥: {e}')
    print('ğŸ’¡ è¯·æ£€æŸ¥.envæ–‡ä»¶æ˜¯å¦æ­£ç¡®é…ç½®')
"
```

## ğŸ¤– LLMæä¾›å•†é…ç½®

### OpenAIå®˜æ–¹

```bash
LLM_MODEL_ID=gpt-3.5-turbo
LLM_API_KEY=sk-your_openai_api_key_here
LLM_BASE_URL=https://api.openai.com/v1
```

**è·å–APIå¯†é’¥**: [OpenAI Platform](https://platform.openai.com/api-keys)

### DeepSeek

```bash
LLM_MODEL_ID=deepseek-chat
LLM_API_KEY=sk-your_deepseek_api_key_here
LLM_BASE_URL=https://api.deepseek.com
```

**è·å–APIå¯†é’¥**: [DeepSeek Platform](https://platform.deepseek.com/)

### é€šä¹‰åƒé—®ï¼ˆé˜¿é‡Œäº‘ï¼‰

```bash
LLM_MODEL_ID=qwen-plus
LLM_API_KEY=sk-your_dashscope_api_key_here
LLM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
```

**è·å–APIå¯†é’¥**: [é˜¿é‡Œäº‘DashScope](https://dashscope.console.aliyun.com/)

### æœˆä¹‹æš—é¢ Kimi

```bash
LLM_MODEL_ID=moonshot-v1-8k
LLM_API_KEY=sk-your_kimi_api_key_here
LLM_BASE_URL=https://api.moonshot.cn/v1
```

**è·å–APIå¯†é’¥**: [Kimiå¼€æ”¾å¹³å°](https://platform.moonshot.cn/)

### æ™ºè°±AI GLM

```bash
LLM_MODEL_ID=glm-4
LLM_API_KEY=your_api_key.your_secret
LLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4
```

**è·å–APIå¯†é’¥**: [æ™ºè°±AIå¼€æ”¾å¹³å°](https://open.bigmodel.cn/)

### ModelScope é­”æ­ç¤¾åŒº

```bash
LLM_MODEL_ID=Qwen/Qwen2.5-72B-Instruct
LLM_API_KEY=ms-your_modelscope_api_key_here
LLM_BASE_URL=https://api-inference.modelscope.cn/v1/
```

**è·å–APIå¯†é’¥**: [ModelScope](https://modelscope.cn/my/myaccesstoken)

## ğŸ  æœ¬åœ°éƒ¨ç½²é…ç½®

### Ollama

```bash
LLM_MODEL_ID=llama3.2
LLM_API_KEY=ollama
LLM_BASE_URL=http://localhost:11434/v1
```

**å®‰è£…æŒ‡å—**: å‚è€ƒ [æœ¬åœ°éƒ¨ç½²æŒ‡å—](./LOCAL_DEPLOYMENT_GUIDE.md)

### vLLM

```bash
LLM_MODEL_ID=meta-llama/Llama-2-7b-chat-hf
LLM_API_KEY=vllm
LLM_BASE_URL=http://localhost:8000/v1
```

### å…¶ä»–æœ¬åœ°æœåŠ¡

```bash
LLM_MODEL_ID=your-local-model
LLM_API_KEY=local
LLM_BASE_URL=http://localhost:8080/v1
```

## ğŸ› ï¸ å·¥å…·é…ç½®

### æœç´¢å·¥å…·

#### Tavilyæœç´¢ï¼ˆæ¨èï¼‰

```bash
TAVILY_API_KEY=tvly-your_tavily_key_here
```

**è·å–APIå¯†é’¥**: [Tavily](https://tavily.com/)

#### SerpApiæœç´¢ï¼ˆå¤‡é€‰ï¼‰

```bash
SERPAPI_API_KEY=your_serpapi_key_here
```

**è·å–APIå¯†é’¥**: [SerpApi](https://serpapi.com/)

## ğŸ”„ å…¼å®¹æ€§é…ç½®

æ¡†æ¶æ”¯æŒå¤šç§ç¯å¢ƒå˜é‡æ ¼å¼ï¼Œä¼šè‡ªåŠ¨æ£€æµ‹ï¼š

### OpenAIæ ¼å¼
```bash
OPENAI_API_KEY=sk-your_openai_api_key_here
```

### æä¾›å•†ä¸“ç”¨æ ¼å¼
```bash
DEEPSEEK_API_KEY=sk-your_deepseek_api_key_here
DASHSCOPE_API_KEY=sk-your_dashscope_api_key_here
MODELSCOPE_API_KEY=ms-your_modelscope_api_key_here
KIMI_API_KEY=sk-your_kimi_api_key_here
ZHIPU_API_KEY=your_zhipu_api_key.your_secret
```

## ğŸ” è‡ªåŠ¨æ£€æµ‹é€»è¾‘

æ¡†æ¶ä¼šæŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§è‡ªåŠ¨æ£€æµ‹LLMæä¾›å•†ï¼š

1. **APIå¯†é’¥æ ¼å¼åˆ¤æ–­**
   - `ms-` å¼€å¤´ â†’ ModelScope
   - `sk-` å¼€å¤´ â†’ OpenAIç³»åˆ—
   - åŒ…å«`.` â†’ æ™ºè°±AI

2. **Base URLåŸŸååˆ¤æ–­**
   - `api.openai.com` â†’ OpenAI
   - `api.deepseek.com` â†’ DeepSeek
   - `dashscope.aliyuncs.com` â†’ é€šä¹‰åƒé—®
   - `api.moonshot.cn` â†’ Kimi
   - `localhost` â†’ æœ¬åœ°éƒ¨ç½²

3. **ç‰¹å®šç¯å¢ƒå˜é‡æ£€æŸ¥**
   - `OPENAI_API_KEY` â†’ OpenAI
   - `DEEPSEEK_API_KEY` â†’ DeepSeek
   - ç­‰ç­‰...

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨

```python
from hello_agents import HelloAgentsLLM, SimpleAgent

# è‡ªåŠ¨æ£€æµ‹providerï¼ˆæ¨èï¼‰
llm = HelloAgentsLLM()

# åˆ›å»ºAgent
agent = SimpleAgent("AIåŠ©æ‰‹", llm)
response = agent.run("ä½ å¥½ï¼")
print(response)
```

### æ‰‹åŠ¨æŒ‡å®šProvider

```python
# æ‰‹åŠ¨æŒ‡å®šprovider
llm = HelloAgentsLLM(provider="modelscope")

# æˆ–è€…ä¼ å…¥å®Œæ•´é…ç½®
llm = HelloAgentsLLM(
    model="gpt-3.5-turbo",
    api_key="sk-your-key",
    base_url="https://api.openai.com/v1",
    provider="openai"
)
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. APIå¯†é’¥æ— æ•ˆ
```bash
âŒ é”™è¯¯: Invalid API key
```
**è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®ï¼Œæ˜¯å¦æœ‰è¶³å¤Ÿçš„é…é¢

#### 2. ç½‘ç»œè¿æ¥é—®é¢˜
```bash
âŒ é”™è¯¯: Connection timeout
```
**è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–å¢åŠ è¶…æ—¶æ—¶é—´ï¼š
```bash
LLM_TIMEOUT=120
```

#### 3. Provideræ£€æµ‹é”™è¯¯
```bash
âŒ é”™è¯¯: Unknown provider
```
**è§£å†³æ–¹æ¡ˆ**: æ‰‹åŠ¨æŒ‡å®šproviderï¼š
```python
llm = HelloAgentsLLM(provider="your_provider")
```

#### 4. ç¯å¢ƒå˜é‡æœªåŠ è½½
```bash
âŒ é”™è¯¯: APIå¯†é’¥å’ŒæœåŠ¡åœ°å€å¿…é¡»è¢«æä¾›æˆ–åœ¨.envæ–‡ä»¶ä¸­å®šä¹‰
```
**è§£å†³æ–¹æ¡ˆ**: 
1. ç¡®ä¿.envæ–‡ä»¶å­˜åœ¨ä¸”é…ç½®æ­£ç¡®
2. æ£€æŸ¥.envæ–‡ä»¶æ˜¯å¦åœ¨æ­£ç¡®çš„ç›®å½•ä¸‹
3. ä½¿ç”¨ç¯å¢ƒå˜é‡æ£€æŸ¥å‘½ä»¤éªŒè¯é…ç½®

### è°ƒè¯•å‘½ä»¤

```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡åŠ è½½
python -c "
import os
from dotenv import load_dotenv
load_dotenv()
print('ğŸ”§ ç¯å¢ƒå˜é‡æ£€æŸ¥:')
print(f'LLM_MODEL_ID: {os.getenv(\"LLM_MODEL_ID\", \"æœªè®¾ç½®\")}')
print(f'LLM_API_KEY: {\"å·²è®¾ç½®\" if os.getenv(\"LLM_API_KEY\") else \"æœªè®¾ç½®\"}')
print(f'LLM_BASE_URL: {os.getenv(\"LLM_BASE_URL\", \"æœªè®¾ç½®\")}')
"

# æµ‹è¯•è¿æ¥ï¼ˆä»…åœ¨é…ç½®æ­£ç¡®æ—¶è¿è¡Œï¼‰
python -c "
from hello_agents import HelloAgentsLLM
try:
    llm = HelloAgentsLLM()
    print(f'âœ… Provider: {llm.provider}')
    print(f'âœ… Model: {llm.model}')
    print('âœ… è¿æ¥æµ‹è¯•æˆåŠŸ')
except Exception as e:
    print(f'âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {e}')
"
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [æœ¬åœ°éƒ¨ç½²æŒ‡å—](./LOCAL_DEPLOYMENT_GUIDE.md) - Ollamaã€vLLMéƒ¨ç½²
- [APIæ–‡æ¡£](../api/) - è¯¦ç»†çš„APIå‚è€ƒ
- [ç¤ºä¾‹ä»£ç ](../../examples/) - å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹

## ğŸ’¬ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é…ç½®é—®é¢˜ï¼Œå¯ä»¥ï¼š

1. æŸ¥çœ‹ [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤) éƒ¨åˆ†
2. è¿è¡Œè°ƒè¯•å‘½ä»¤æ£€æŸ¥é…ç½®
3. æŸ¥çœ‹é¡¹ç›®çš„ Issues é¡µé¢
4. å‚è€ƒç¤ºä¾‹ä»£ç ä¸­çš„é…ç½®
